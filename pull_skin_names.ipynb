{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping a List of All Counter Strike: Global Offensive Items\n",
    "\n",
    "## Why?\n",
    "Counter Strike has thousands of different items that can be trading and sold on the community market. On the internet, there is **no comprehensive list of skins and cosmetics** for us to use to collect data. Previous methods of analyzing the CS:GO market queried the community market for all items. This method, however, leaves out crucial information on a skin's quality and collection. Thus I built this notebook to collect a list of all skins and items from the website csgostash.com. \n",
    "\n",
    "## xlsx\n",
    ".xlsx files were used instead of .csv to allow for symbols to be written. Many skins have asian characters or special characters that are necessary for querying later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://csgostash.com/\"\n",
    "\n",
    "html_content = requests.get(url).text\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAPING ALL GUN SKINS\n",
    "\n",
    "To scrape all gun skins, I compiled a list of links to every weapon's page of skins on csgostash.com as well and pulled crucial information on collection and quality. Skins also have a unique quality called souvenir which can later be queried for as a separate item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skins = pd.DataFrame(columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\", \"Souvenir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the list of all weapon links\n",
    "skin_ul = soup.find_all(\"ul\", {\"class\": \"dropdown-menu navbar-dropdown-large\"})\n",
    "\n",
    "skin_links = []\n",
    "for x in skin_ul[:4]: # sliced to just the guns\n",
    "    skin_children = x.findChildren(\"a\", href = True)\n",
    "\n",
    "    for child in skin_children:\n",
    "        skin_links.append(child[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skins(items):\n",
    "    skins = []\n",
    "    for weapon in reversed(items[:-1]): # sliced to ignore default\n",
    "        try:\n",
    "            skin = weapon.h3.text\n",
    "            gun = link.split(\"/\")[-1].replace(\"+\", \" \") # accounts for weapons like r8 which have a space\n",
    "            quality = weapon.p.text.split()[0]\n",
    "            if (quality == \"Consumer\") | (quality == \"Industrial\"):\n",
    "                quality += \" Grade\"\n",
    "            collection = weapon.find(\"div\", {\"class\": \"collection\"}).text.replace(\"\\n\", \"\")\n",
    "            st = weapon.find(\"div\", {\"class\": \"stattrak\"})\n",
    "            if st == None:\n",
    "                stattrak = False\n",
    "            else:\n",
    "                stattrak = True\n",
    "\n",
    "            sv = weapon.find(\"div\", {\"class\": \"souvenir\"})\n",
    "            if sv == None:\n",
    "                souvenir = False\n",
    "            else:\n",
    "                souvenir = True\n",
    "            skins.append([gun, collection, skin, quality, stattrak, souvenir])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return skins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for link in skin_links:\n",
    "    soup = BeautifulSoup(requests.get(link).content, \"lxml\")\n",
    "    items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "    skins = skins.append(pd.DataFrame(data = get_skins(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\", \"Souvenir\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skins.to_excel(\"skins.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAPING ALL KNIVES AND GLOVES\n",
    "\n",
    "In order to scrape all knives, we used the collections pages on CS:GO STASH instead of just a list of knives. This is due to the fact knives can reappear in different collections, making it difficult to scrape the exact collection knives are in. \n",
    "\n",
    "Note: Knives are categorized by the first box they appeared in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knives = pd.DataFrame(columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\", \"Souvenir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fetching link of all collections\n",
    "knives_ul = soup.find(\"ul\", {\"class\": \"dropdown-menu navbar-dropdown-small\"})\n",
    "\n",
    "knives_links = []\n",
    "knives_children = knives_ul.findChildren(\"a\", href = True)\n",
    "\n",
    "for child in knives_children:\n",
    "    knives_links.append(child[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_knives(items):\n",
    "    skins = []\n",
    "    for weapon in reversed(items):\n",
    "        try:\n",
    "            x = weapon.h3.text.split(\" | \")\n",
    "            gun = \"â˜… \" + x[0] # star used in querying\n",
    "            skin = x[1]\n",
    "            collection = link.split(\"/\")[-1].replace(\"-\", \" \")\n",
    "            quality = weapon.p.text.split()[0]\n",
    "            stattrak = True # all knives have a stattrak variant\n",
    "            skins.append([gun, collection, skin, quality, stattrak])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return skins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for link in knives_links[:-3]: # slice off last 3 as are not cases\n",
    "    start = link + \"?Knives=1\" # navigates to the knives page\n",
    "    url = link + \"?Knives=1&page={}\"\n",
    "\n",
    "    soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "    try: # checks if there are multiple pages\n",
    "        page_selector = soup.find(\"ul\", {\"class\": \"pagination\"})\n",
    "        page_children = page_selector.findChildren(\"a\", href = True)\n",
    "\n",
    "        pages = int(page_children[-2].text.split(None, 1)[0])\n",
    "    except:\n",
    "        pages = 1\n",
    "    \n",
    "    for page in range(pages, 0, -1): # loops through the different pages to get all items\n",
    "        soup = BeautifulSoup(requests.get(url.format(page)).content, \"lxml\")\n",
    "        items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "        knives = knives.append(pd.DataFrame(data = get_knives(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\"]), ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gloves(items):\n",
    "    skins = []\n",
    "    for weapon in reversed(items):\n",
    "        try:\n",
    "            x = weapon.h3.text.split(\" | \")\n",
    "            gun = x[0]\n",
    "            skin = x[1]\n",
    "            collection = link.split(\"/\")[-1].replace(\"-\", \" \")\n",
    "            quality = weapon.p.text.split()[0]\n",
    "            stattrak = False # gloves dont have a stattrak version\n",
    "            skins.append([gun, collection, skin, quality, stattrak]) \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return skins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loops through all gloves\n",
    "glove_links = [\"https://csgostash.com/case/179/Glove-Case\", \"https://csgostash.com/case/238/Clutch-Case\"]\n",
    "\n",
    "for link in glove_links:\n",
    "    start = link + \"?Gloves=1\" # navigates to the gloves page\n",
    "    url = link + \"?Gloves=1&page={}\"\n",
    "\n",
    "    soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "    try: # checks if there are multiple pages\n",
    "        page_selector = soup.find(\"ul\", {\"class\": \"pagination\"})\n",
    "        page_children = page_selector.findChildren(\"a\", href = True)\n",
    "\n",
    "        pages = int(page_children[-2].text.split(None, 1)[0])\n",
    "    except:\n",
    "        pages = 1\n",
    "    for page in range(pages, 0, -1): # loops through the different pages to get all items\n",
    "        soup = BeautifulSoup(requests.get(url.format(page)).content, \"lxml\")\n",
    "        items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "        knives = knives.append(pd.DataFrame(data = get_gloves(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knives.to_excel(\"knivesgloves.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAPING ALL STICKERS\n",
    "\n",
    "Stickers can vary as they can be apart of different tournaments and collections. Thus we categorize them by their collection if it exists or by the tournament they were released in. Certain collections (slid3, team roles, and pinup) have multiple foil and holo stickers due to a Valve mess up on the item name. These were added later manually and the sticker list reflects this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stickers = pd.DataFrame(columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pull tournament stickers\n",
    "def get_stickers(items):\n",
    "    sticks = []\n",
    "    for x in reversed(items): \n",
    "        try:\n",
    "            weapon = \"Sticker\"\n",
    "            name = x.h3.text\n",
    "            quality = x.p.text.split()[0]\n",
    "            if (quality == \"High\"):\n",
    "                quality += \" Grade\"\n",
    "            collection = x.h4.text\n",
    "            sticks.append([weapon, collection, name, quality])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return sticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterates through the tournament stickers pages\n",
    "start = \"https://csgostash.com/stickers/tournament\"\n",
    "url = \"https://csgostash.com/stickers/tournament\" + \"?page={}\"\n",
    "\n",
    "soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "try: # checks if there are multiple pages\n",
    "    page_selector = soup.find(\"ul\", {\"class\": \"pagination\"})\n",
    "    page_children = page_selector.findChildren(\"a\", href = True)\n",
    "\n",
    "    pages = int(page_children[-2].text.split(None, 1)[0])\n",
    "except:\n",
    "    pages = 1\n",
    "\n",
    "for page in range(pages, 0, -1): # loops through the different pages to get all items\n",
    "    soup = BeautifulSoup(requests.get(url.format(page)).content, \"lxml\")\n",
    "    items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "    stickers = stickers.append(pd.DataFrame(data = get_stickers(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pull normal stickers\n",
    "def get_stickers(items):\n",
    "    sticks = []\n",
    "    for x in reversed(items): \n",
    "        try:\n",
    "            weapon = \"Sticker\"\n",
    "            name = x.h3.text\n",
    "            quality = x.p.text.split()[0]\n",
    "            if (quality == \"High\"):\n",
    "                quality += \" Grade\"\n",
    "            if quality == \"Contraband\": # contraband doesnt have collection\n",
    "                collection = None\n",
    "            else:\n",
    "                collection = x.find(\"p\", {\"class\": \"nomargin item-resultbox-collection-container-info\"}).text.replace(\"\\n\", \"\")\n",
    "            sticks.append([weapon, collection, name, quality])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return sticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterates through the regular stickers pages\n",
    "start = \"https://csgostash.com/stickers/regular\"\n",
    "url = \"https://csgostash.com/stickers/regular\" + \"?page={}\"\n",
    "\n",
    "soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "try: # checks if there are multiple pages\n",
    "    page_selector = soup.find(\"ul\", {\"class\": \"pagination\"})\n",
    "    page_children = page_selector.findChildren(\"a\", href = True)\n",
    "\n",
    "    pages = int(page_children[-2].text.split(None, 1)[0])\n",
    "except:\n",
    "    pages = 1\n",
    "\n",
    "for page in range(pages, 0, -1): # loops through the different pages to get all items\n",
    "    soup = BeautifulSoup(requests.get(url.format(page)).content, \"lxml\")\n",
    "    items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "    stickers = stickers.append(pd.DataFrame(data = get_stickers(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stickers.to_excel(\"stickers.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAPING ALL CASES\n",
    "Cases are a valuable trading commodity that used to be a viable investment choice. To scrape them, we have to be careful of major sticker capsules which are placed in the collection under their respective major."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand created a list of list for the types of cases not included on csgostash\n",
    "uncategorized = [[\"Patch Pack\", \"Half-Life: Alyx Patch Pack\", \"Half-Life: Alyx Patch Pack\"], [\"Patch Pack\", \"CS:GO Patch Pack\", \"CS:GO Patch Pack\"], [\"Music Kit Box\", \"Masterminds Music Kit Box\", \"Masterminds Music Kit Box\"], [\"Must Kit Box\", \"StatTrakâ„¢ Radicals Box\", \"StatTrakâ„¢ Radicals Box\"], [\"Pins Capsule\", \"Collectible Pins Capsule Series 1\", \"Collectible Pins Capsule Series 1\"], [\"Pins Capsule\", \"Collectible Pins Capsule Series 2\", \"Collectible Pins Capsule Series 2\"], [\"Pins Capsule\", \"Collectible Pins Capsule Series 3\", \"Collectible Pins Capsule Series 3\"], [\"Pins Capsule\", \"Half-Life: Alyx Collectible Pins Capsule\", \"Half-Life: Alyx Collectible Pins Capsule\"], [\"Graffiti Box\", \"Community Graffiti Box 1\", \"Community Graffiti Box 1\"], [\"Graffiti Box\", \"CS:GO Graffiti Box\", \"CS:GO Graffiti Box\"], [\"Graffiti Box\", \"Perfect World Graffiti Box\", \"Perfect World Graffiti Box\"]]\n",
    "\n",
    "cases = pd.DataFrame(data = uncategorized, columns = [\"Weapon\", \"Collection\", \"Skin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_links = [\"https://csgostash.com/containers/skin-cases\", \"https://csgostash.com/containers/souvenir-packages\", \"https://csgostash.com/containers/gift-packages\", \"https://csgostash.com/containers/sticker-capsules\", \"https://csgostash.com/containers/autograph-capsules\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases_sc(items, item_type): # get cases with the same collection as their name\n",
    "    case_list = []\n",
    "    for x in reversed(items): \n",
    "        try:\n",
    "            name = x.h4.text # cases have text in h4 instead\n",
    "            if \"201\" in name and \"eSports\" not in name: # checks if its a major sticker capsule\n",
    "                words = name.split()\n",
    "                for x in range(0, len(words)+1):\n",
    "                    if \"201\" in words[x]:\n",
    "                        if words[x-1] == \"Columbus\":\n",
    "                            collection = \" \".join(words[x-2:x+1])\n",
    "                            break\n",
    "                        else:\n",
    "                            collection = \" \".join(words[x-1:x+1])\n",
    "                            break\n",
    "            else:\n",
    "                collection = name\n",
    "            case_list.append([item_type, collection, name])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return case_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for link in (case_links[0], case_links[2], case_links[3], case_links[4]): # links i can get all data from just a header\n",
    "    start = link\n",
    "    url = link + \"?page={}\"\n",
    "\n",
    "    soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "    try: # checks if there are multiple pages\n",
    "        page_selector = soup.find(\"ul\", {\"class\": \"pagination\"})\n",
    "        page_children = page_selector.findChildren(\"a\", href = True)\n",
    "\n",
    "        pages = int(page_children[-2].text.split(None, 1)[0])\n",
    "    except:\n",
    "        pages = 1\n",
    "\n",
    "    for page in range(pages, 0, -1): # loops through the different pages to get all items\n",
    "        soup = BeautifulSoup(requests.get(url.format(page)).content, \"lxml\")\n",
    "        item_type = soup.find(\"div\", {\"class\": \"col-lg-12 text-center col-widen content-header\"}).text.replace(\"\\n\", \"\")\n",
    "        items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "        cases = cases.append(pd.DataFrame(data = get_cases_sc(items, item_type), columns = [\"Weapon\", \"Collection\", \"Skin\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases_souv(items, item_type): # get souvenir cases\n",
    "    case_list = []\n",
    "    for x in reversed(items): \n",
    "        try:\n",
    "            name = x.h4.text # cases have text in h4 instead\n",
    "            collection = x.find(\"div\", {\"class\": \"containers-details-link\"}).text.replace(\"\\n\", \"\")\n",
    "            case_list.append([item_type, collection, name])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return case_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = case_links[1]\n",
    "url = case_links[1] + \"?page={}\"\n",
    "\n",
    "soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "try: # checks if there are multiple pages\n",
    "    page_selector = soup.find(\"ul\", {\"class\": \"pagination\"})\n",
    "    page_children = page_selector.findChildren(\"a\", href = True)\n",
    "\n",
    "    pages = int(page_children[-2].text.split(None, 1)[0])\n",
    "except:\n",
    "    pages = 1\n",
    "\n",
    "for page in range(pages, 0, -1): # loops through the different pages to get all items\n",
    "    soup = BeautifulSoup(requests.get(url.format(page)).content, \"lxml\")\n",
    "    item_type = soup.find(\"div\", {\"class\": \"col-lg-12 text-center col-widen content-header\"}).text.replace(\"\\n\", \"\")\n",
    "    items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "    cases = cases.append(pd.DataFrame(data = get_cases_souv(items, item_type), columns = [\"Weapon\", \"Collection\", \"Skin\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases.to_excel(\"cases.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAPING OTHER\n",
    "There are also a collection of miscellaneous items we can scrape for further insight. Each of these items are scraped separately as their pages all differ in some way or another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = pd.DataFrame(columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents(items): # get agents\n",
    "    case_list = []\n",
    "    for x in reversed(items): \n",
    "        try:\n",
    "            weapon = \"Agents\"\n",
    "            name = x.h3.text # agents are in h3\n",
    "            collection = \"Shattered Web Case\"\n",
    "            quality = x.p.text.split()[0]\n",
    "            stattrak = False\n",
    "            case_list.append([weapon, collection, name, quality, stattrak])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return case_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = \"https://csgostash.com/agents\"\n",
    "\n",
    "soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "other = other.append(pd.DataFrame(data = get_agents(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(items): # get agents patches\n",
    "    case_list = []\n",
    "    for x in reversed(items): \n",
    "        try:\n",
    "            weapon = \"Patch\"\n",
    "            name = x.h3.text # patches are in h3\n",
    "            name = name.replace(\" Patch\", \"\") # replace patch in name for easier scraping later\n",
    "            quality = x.p.text.split()[0]\n",
    "            collection = x.find(\"p\", {\"class\": \"nomargin item-resultbox-collection-container-info\"}).text.replace(\"\\n\", \"\")\n",
    "            stattrak = False\n",
    "            case_list.append([weapon, collection, name, quality, stattrak])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return case_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = \"https://csgostash.com/patches\"\n",
    "\n",
    "soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "other = other.append(pd.DataFrame(data = get_patches(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kits(items): # get music kits\n",
    "    case_list = []\n",
    "    for x in reversed(items): \n",
    "        try:\n",
    "            weapon = \"Music Kit\"\n",
    "            title = x.h3.text # name is in h3\n",
    "            author = \" \".join(x.h4.text.split()[1:]) # get author\n",
    "            name = \"{0}, {1}\".format(author, title)\n",
    "            quality = \"High Grade\"\n",
    "            collection = x.find(\"p\", {\"class\": \"nomargin item-resultbox-collection-container-info\"})\n",
    "            if collection == None:\n",
    "                collection = None\n",
    "            elif collection.text.replace(\"\\n\", \"\") == \"Found in 2 boxes\": #  finds the master mind collections\n",
    "                collection = \"Masterminds Music Kit Box\"\n",
    "            else:\n",
    "                collection = collection.text\n",
    "\n",
    "            st = x.find(\"div\", {\"class\": \"stattrak\"})\n",
    "            if st == None:\n",
    "                stattrak = False\n",
    "            elif st.text.replace(\"\\n\", \"\") == \"StatTrak Available\":\n",
    "                stattrak = True\n",
    "            elif st.text.replace(\"\\n\", \"\") == \"StatTrak Only\": # if stattrak only, make the name show it to make querying data easier later\n",
    "                name = \"StatTrakâ„¢ Music Kit | \" + name\n",
    "                stattrak = False\n",
    "                    \n",
    "            case_list.append([weapon, collection, name, quality, stattrak])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return case_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = \"https://csgostash.com/music\"\n",
    "\n",
    "soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "other = other.append(pd.DataFrame(data = get_kits(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pins(items): # get pins\n",
    "    case_list = []\n",
    "    for x in reversed(items): \n",
    "        try:\n",
    "            weapon = \"Collectible Pins\"\n",
    "            name = x.h3.text # pins are in h3\n",
    "            quality = x.p.text.split()[0]\n",
    "            if quality == \"High\":\n",
    "                quality = \"High Grade\"\n",
    "            collection = x.find(\"p\", {\"class\": \"nomargin item-resultbox-collection-container-info\"}).text.replace(\"\\n\", \"\")\n",
    "            stattrak = False\n",
    "            case_list.append([weapon, collection, name, quality, stattrak])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return case_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = \"https://csgostash.com/pins\"\n",
    "\n",
    "soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "other = other.append(pd.DataFrame(data = get_pins(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graffiti(items): # get graffiti\n",
    "    case_list = []\n",
    "    for x in reversed(items): \n",
    "        \n",
    "        try:\n",
    "            weapon = \"Sealed Graffiti\"\n",
    "            name = x.h3.text.replace(\"\\n\", \"\") # graffitis are in h3\n",
    "            if \"201\" in name:\n",
    "                words = name.split()\n",
    "                for i in range(0, len(words)+1):\n",
    "                    if \"201\" in words[i]: # checks if its a major sticker capsule\n",
    "                        collection = \" \".join(words[i-1:i+1])\n",
    "                        break\n",
    "            else:\n",
    "                collection = x.find(\"p\", {\"class\": \"nomargin item-resultbox-collection-container-info\"}).text.replace(\"\\n\", \"\")\n",
    "            quality = x.p.text.split()[0]\n",
    "            if quality == \"High\":\n",
    "                quality = \"High Grade\"\n",
    "            elif quality == \"Base\": # base grade graffitis are not in a collection\n",
    "                quality = \"Base Grade\"\n",
    "                collection = None\n",
    "            stattrak = False\n",
    "            \n",
    "            if quality == \"Base Grade\": # consumer sprays have a variant of colors which all must be added\n",
    "                colors = (\"Wire Blue\", \"SWAT Blue\", \"Monarch Blue\", \"Jungle Green\", \"Blood Red\", \"Dust Brown\", \"Desert Amber\", \"Brick Red\", # some items dont have all these colors\n",
    "                        \"Cash Green\", \"Frog Green\", \"Battle Green\", \"Monster Purple\", \"Shark White\", \"Tracer Yellow\", \"Bazooka Pink\", \n",
    "                        \"Violent Violet\", \"Princess Pink\", \"Tiger Orange\", \"War Pig Pink\")\n",
    "                for c in colors:\n",
    "                    colored_name = name + f\" ({c})\"\n",
    "                    case_list.append([weapon, collection, colored_name, quality, stattrak])\n",
    "            else:\n",
    "                case_list.append([weapon, collection, name, quality, stattrak])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return case_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = \"https://csgostash.com/graffiti\"\n",
    "url = \"https://csgostash.com/graffiti\" + \"?page={}\"\n",
    "\n",
    "soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "try: # checks if there are multiple pages\n",
    "    page_selector = soup.find(\"ul\", {\"class\": \"pagination\"})\n",
    "    page_children = page_selector.findChildren(\"a\", href = True)\n",
    "\n",
    "    pages = int(page_children[-2].text.split(None, 1)[0])\n",
    "except:\n",
    "    pages = 1\n",
    "\n",
    "for page in range(pages, 0, -1): # loops through the different pages to get all items\n",
    "    soup = BeautifulSoup(requests.get(url.format(page)).content, \"lxml\")\n",
    "    items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "    other = other.append(pd.DataFrame(data = get_graffiti(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(items): # get pins\n",
    "    case_list = []\n",
    "    for x in reversed(items): \n",
    "        try:\n",
    "            weapon = \"Items\"\n",
    "            name = x.h4.text # keys are in h4\n",
    "            quality = None\n",
    "            collection = None\n",
    "            stattrak = False\n",
    "            case_list.append([\"Items\", collection, name, quality, stattrak])\n",
    "        except Exception as e: # accounts for ad spaces\n",
    "            pass\n",
    "\n",
    "    return case_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = \"https://csgostash.com/items\"\n",
    "\n",
    "soup = BeautifulSoup(requests.get(start).content, \"lxml\")\n",
    "items = soup.find_all(\"div\", class_= \"well result-box nomargin\")\n",
    "other = other.append(pd.DataFrame(data = get_keys(items), columns = [\"Weapon\", \"Collection\", \"Skin\", \"Quality\", \"StatTrak\"]), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other.to_excel(\"other.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('datascience': conda)",
   "name": "python_defaultSpec_1600241505885"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}