{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Datasets of the Market History of all Counter Strike: Global Offensive Items\n",
    "\n",
    "This notebook includes all the code written to scrape market history from steam json requests. I am still exploring/learning web scraping so the code may not be the best as I tried to experiment with new methods and technologies. Steam has multiple naming irregularities as well as rate limiting that made some manual data cleaning necessary. If you want to rescrape all data, change the values in the third cell of this notebook. Total data scraping time (excluding coding time) was approximately 12 hours. \n",
    "\n",
    "Data is split up into multiple xlsx files to account for potential crashes or errors in data collection (there were many).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime, date\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings Cell\n",
    "appid = 730 #CSGO\n",
    "currency = 1 # USD\n",
    "country = \"US\"\n",
    "cookie = {\"steamLoginSecure\": \"PLACEHOLDER\"} # steamloginsecure cookie. Please enter in your own for this to work properly\n",
    "\n",
    "FN = \"Factory New\"\n",
    "MW = \"Minimal Wear\"\n",
    "FT = \"Field-Tested\"\n",
    "WW = \"Well-Worn\"\n",
    "BS = \"Battle-Scarred\"\n",
    "\n",
    "starting_date = date(2013, 8, 1) # originally scraped from 8-1-2013 but upon data analysis found the first date of market sales is 8-13-2013\n",
    "ending_date = date(2020, 9, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of dates in the date range for comparison to data pulled from the market later\n",
    "dates_list = pd.date_range(start = starting_date, end = ending_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_history\n",
    "\n",
    "get_history() is the primary function used to pull data from the Steam server using a json get request with the item name and symbols formatted to ASCII. Steam servers will return a status indicating whether the request was successful and a list of prices and the volume sold for each particular date. If a date sold nothing, there is no entry and the list simply skips that date. In order to combat this we use date_list, a list of every date in between our given range. Each date in the date list is compared to the date given in the steam data. If the steam data date does not match, we append a None, None to the price/volume list and increase the date_list index up again until the data has another value. \n",
    "\n",
    "This function underwent multiple revisions. Other possible variants include checking the difference between the current date and the previous date and appending Nones based on that value.\n",
    "\n",
    "Steam also gives hourly? (unsure if hourly but seems so) price data for more recent dates. This means a date can appear multiple times. In order to address this, data with the same date as the previous data entry is aggregated together (price is averaged and volume is summed).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(name):\n",
    "    url = \"http://steamcommunity.com/market/pricehistory/?country={0}&currency={1}&appid={2}&market_hash_name={3}\".format(country, currency, appid, name)\n",
    "\n",
    "    for x in range(3): # occasionally will hit connection errors\n",
    "        try:\n",
    "            item = requests.get(url, cookies = cookie)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            if x == 2:\n",
    "                return 1\n",
    "            else:\n",
    "                time.sleep(60) # waits 60 seconds to allow steam to refresh\n",
    "                continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    item = item.content\n",
    "    item = json.loads(item)\n",
    "\n",
    "    if item: # checks if returned anything\n",
    "        item_prices = item[\"prices\"] \n",
    "        success = item[\"success\"]\n",
    "        if (item_prices == False) | (not item_prices) | (success == False):\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"{0} CURRENTLY SCRAPING ITEM: {1}, NUMBER {2} OF {3} ITEMS\".format(datetime.now(), name, current_num, total_items)) # status check\n",
    "            pricevol = [] # price and volume are combined for multiindexing in the dataframe later\n",
    "            dates = [] # used to check whether dates repeat\n",
    "            item_counter = 0 \n",
    "            date_counter = -1\n",
    "\n",
    "            while (date_counter < len(dates_list) - 1) & (item_counter < len(item_prices)):\n",
    "                date_counter += 1\n",
    "                current_date = datetime.strptime(item_prices[item_counter][0][0:11], \"%b %d %Y\").date()\n",
    "                if (current_date == dates_list[date_counter - 1]): # some entries have multiple entries per day\n",
    "                    pricevol[-2] = np.mean([item_prices[item_counter][1], pricevol[-2]]) # averages the prices in the day and rewrites the previously written one\n",
    "                    pricevol[-1] = int(item_prices[item_counter][2]) + pricevol[-1] # adds the volumes for the day together\n",
    "                    date_counter -= 1\n",
    "                    item_counter += 1\n",
    "                elif dates_list[date_counter] != current_date:\n",
    "                    pricevol.extend((None, None))\n",
    "                else:\n",
    "                    pricevol.append(item_prices[item_counter][1]) # appending price\n",
    "                    pricevol.append(int(item_prices[item_counter][2])) # appending volume\n",
    "                    dates.append(current_date) # appending the date into a list\n",
    "                    item_counter += 1\n",
    "        \n",
    "            if current_date != ending_date: # adds extra nones to end if the present has no sales\n",
    "                diff = ending_date - current_date\n",
    "                pricevol.extend([None for x in range(0, diff.days * 2)])\n",
    "    else:\n",
    "        print(\"No contents on {}\".format(name))\n",
    "        return 1\n",
    "    return pricevol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weapon Skins Price History Collection\n",
    "\n",
    "Scraping weapon skins involves formatting the skin's name and iterating through all possible conditions, souvenir, and StatTrak variants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             Weapon                Collection            Skin         Quality  \\\n0         CZ75-Auto    The Baggage Collection     Green Plaid  Consumer Grade   \n1         CZ75-Auto  The Chop Shop Collection      Army Sheen  Consumer Grade   \n2         CZ75-Auto     The Canals Collection          Indigo  Consumer Grade   \n3         CZ75-Auto       The Bank Collection          Tuxedo        Mil-Spec   \n4         CZ75-Auto   The Overpass Collection           Nitro        Mil-Spec   \n...             ...                       ...             ...             ...   \n1293     Hand Wraps               Clutch Case   Cobalt Skulls   Extraordinary   \n1294  Driver Gloves               Clutch Case    Racing Green   Extraordinary   \n1295  Driver Gloves               Clutch Case        Overtake   Extraordinary   \n1296  Driver Gloves               Clutch Case  Imperial Plaid   Extraordinary   \n1297  Driver Gloves               Clutch Case      King Snake   Extraordinary   \n\n      StatTrak  Souvenir  \n0        False     False  \n1        False     False  \n2        False     False  \n3        False     False  \n4        False      True  \n...        ...       ...  \n1293     False     False  \n1294     False     False  \n1295     False     False  \n1296     False     False  \n1297     False     False  \n\n[1298 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Weapon</th>\n      <th>Collection</th>\n      <th>Skin</th>\n      <th>Quality</th>\n      <th>StatTrak</th>\n      <th>Souvenir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CZ75-Auto</td>\n      <td>The Baggage Collection</td>\n      <td>Green Plaid</td>\n      <td>Consumer Grade</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CZ75-Auto</td>\n      <td>The Chop Shop Collection</td>\n      <td>Army Sheen</td>\n      <td>Consumer Grade</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CZ75-Auto</td>\n      <td>The Canals Collection</td>\n      <td>Indigo</td>\n      <td>Consumer Grade</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CZ75-Auto</td>\n      <td>The Bank Collection</td>\n      <td>Tuxedo</td>\n      <td>Mil-Spec</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CZ75-Auto</td>\n      <td>The Overpass Collection</td>\n      <td>Nitro</td>\n      <td>Mil-Spec</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1293</th>\n      <td>Hand Wraps</td>\n      <td>Clutch Case</td>\n      <td>Cobalt Skulls</td>\n      <td>Extraordinary</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>Driver Gloves</td>\n      <td>Clutch Case</td>\n      <td>Racing Green</td>\n      <td>Extraordinary</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1295</th>\n      <td>Driver Gloves</td>\n      <td>Clutch Case</td>\n      <td>Overtake</td>\n      <td>Extraordinary</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1296</th>\n      <td>Driver Gloves</td>\n      <td>Clutch Case</td>\n      <td>Imperial Plaid</td>\n      <td>Extraordinary</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1297</th>\n      <td>Driver Gloves</td>\n      <td>Clutch Case</td>\n      <td>King Snake</td>\n      <td>Extraordinary</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>1298 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "all_skins = pd.read_excel(\"items_list/skins_list.xlsx\")\n",
    "\n",
    "knives = pd.read_excel(\"items_list/knivesgloves_list.xlsx\")\n",
    "all_skins = all_skins.append(knives, ignore_index = True)\n",
    "\n",
    "all_skins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hash_name(weapon, skin, condition, st, sv):\n",
    "    if skin == \"★ (Vanilla)\":\n",
    "        name = \"{0}\".format(weapon) # vanilla knives have no condition or skin name\n",
    "    else:\n",
    "        name = \"{0} | {1} ({2})\".format(weapon, skin, condition)\n",
    "        \n",
    "    if st == True:\n",
    "        name = \"StatTrak™ \" + name\n",
    "    elif sv == True: \n",
    "        name = \"Souvenir \" + name\n",
    "        \n",
    "    if (\"Knife\" in weapon) | (\"Gloves\" in weapon): # knives and gloves have a star before their name\n",
    "        name = \"★ \" + name\n",
    "        \n",
    "    formatted_name = name.replace(\" \", \"%20\") \n",
    "    formatted_name = formatted_name.replace(\"&\", \"%26\")\n",
    "    formatted_name = formatted_name.replace(\"|\", \"%7C\")\n",
    "    formatted_name = formatted_name.replace(\"+\", \"%2B\")\n",
    "    formatted_name = formatted_name.replace(\":\", \"%3A\")\n",
    "    formatted_name = formatted_name.replace(\"/\", \"%2F\")\n",
    "    formatted_name = formatted_name.replace(\"(\", \"%28\")\n",
    "    formatted_name = formatted_name.replace(\")\", \"%29\")\n",
    "\n",
    "    return formatted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False False\n2020-09-17 16:50:01.627348 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Green%20Plaid%20%28Battle-Scarred%29, NUMBER 1 OF 1298 ITEMS\n2020-09-17 16:50:04.807113 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Green%20Plaid%20%28Well-Worn%29, NUMBER 1 OF 1298 ITEMS\n2020-09-17 16:50:06.298748 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Green%20Plaid%20%28Field-Tested%29, NUMBER 1 OF 1298 ITEMS\n2020-09-17 16:50:09.400913 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Green%20Plaid%20%28Minimal%20Wear%29, NUMBER 1 OF 1298 ITEMS\n2020-09-17 16:50:12.419977 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Green%20Plaid%20%28Factory%20New%29, NUMBER 1 OF 1298 ITEMS\nFalse False\nCZ75-Auto%20%7C%20Army%20Sheen%20%28Battle-Scarred%29 HAS FAILED\nCZ75-Auto%20%7C%20Army%20Sheen%20%28Well-Worn%29 HAS FAILED\n2020-09-17 16:50:17.718630 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Army%20Sheen%20%28Field-Tested%29, NUMBER 2 OF 1298 ITEMS\n2020-09-17 16:50:22.475005 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Army%20Sheen%20%28Minimal%20Wear%29, NUMBER 2 OF 1298 ITEMS\n2020-09-17 16:50:25.257274 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Army%20Sheen%20%28Factory%20New%29, NUMBER 2 OF 1298 ITEMS\nFalse False\n2020-09-17 16:50:29.264707 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Indigo%20%28Battle-Scarred%29, NUMBER 3 OF 1298 ITEMS\n2020-09-17 16:50:31.010107 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Indigo%20%28Well-Worn%29, NUMBER 3 OF 1298 ITEMS\n2020-09-17 16:50:33.383986 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Indigo%20%28Field-Tested%29, NUMBER 3 OF 1298 ITEMS\n2020-09-17 16:50:36.573387 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Indigo%20%28Minimal%20Wear%29, NUMBER 3 OF 1298 ITEMS\n2020-09-17 16:50:39.844057 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Indigo%20%28Factory%20New%29, NUMBER 3 OF 1298 ITEMS\nFalse False\n2020-09-17 16:50:41.392991 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Tuxedo%20%28Battle-Scarred%29, NUMBER 4 OF 1298 ITEMS\n2020-09-17 16:50:44.236307 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Tuxedo%20%28Well-Worn%29, NUMBER 4 OF 1298 ITEMS\n2020-09-17 16:50:45.629184 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Tuxedo%20%28Field-Tested%29, NUMBER 4 OF 1298 ITEMS\n2020-09-17 16:50:47.689058 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Tuxedo%20%28Minimal%20Wear%29, NUMBER 4 OF 1298 ITEMS\n2020-09-17 16:50:50.496083 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Tuxedo%20%28Factory%20New%29, NUMBER 4 OF 1298 ITEMS\nFalse False\n2020-09-17 16:50:53.287317 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Nitro%20%28Battle-Scarred%29, NUMBER 5 OF 1298 ITEMS\n2020-09-17 16:50:56.195414 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Nitro%20%28Well-Worn%29, NUMBER 5 OF 1298 ITEMS\n2020-09-17 16:50:57.807997 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Nitro%20%28Field-Tested%29, NUMBER 5 OF 1298 ITEMS\n2020-09-17 16:51:01.321851 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Nitro%20%28Minimal%20Wear%29, NUMBER 5 OF 1298 ITEMS\n2020-09-17 16:51:03.109759 CURRENTLY SCRAPING ITEM: CZ75-Auto%20%7C%20Nitro%20%28Factory%20New%29, NUMBER 5 OF 1298 ITEMS\nFalse True\n2020-09-17 16:51:06.691377 CURRENTLY SCRAPING ITEM: Souvenir%20CZ75-Auto%20%7C%20Nitro%20%28Battle-Scarred%29, NUMBER 5 OF 1298 ITEMS\n2020-09-17 16:51:08.886939 CURRENTLY SCRAPING ITEM: Souvenir%20CZ75-Auto%20%7C%20Nitro%20%28Well-Worn%29, NUMBER 5 OF 1298 ITEMS\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f80ad28c3a23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mpossible_conditions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFT\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mMW\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mFN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcondition\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossible_conditions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# iterates through all possible conditions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# avoid steam rate limiting with a random sleep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_hash_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Weapon\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Skin\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mprice_vol_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skin_history = {}\n",
    "i = 0\n",
    "current_num = 0\n",
    "total_items = len(all_skins.index)\n",
    "\n",
    "for index, row in all_skins.iterrows():\n",
    "    current_num += 1\n",
    "    # checks whether to reiterate for stattrak and souvenir\n",
    "    if (row[\"StatTrak\"] == True) | (row[\"Souvenir\"] == True):\n",
    "        svst = ((False, False), (row[\"StatTrak\"], row[\"Souvenir\"]))\n",
    "    else:\n",
    "        svst = ((False, False),)\n",
    "    for st, sv in svst:\n",
    "        if row[\"Skin\"] == \"★ (Vanilla)\":\n",
    "            possible_conditions = (None,)\n",
    "        else:\n",
    "            possible_conditions = (BS, WW, FT , MW , FN)\n",
    "        for condition in possible_conditions: # iterates through all possible conditions\n",
    "            time.sleep(random.uniform(.5, 3)) # avoid steam rate limiting with a random sleep\n",
    "            name = make_hash_name(row[\"Weapon\"], row[\"Skin\"], condition, st, sv)\n",
    "            price_vol_history = get_history(name)\n",
    "            if price_vol_history == 1:\n",
    "                print(\"{0} HAS FAILED\".format(name))\n",
    "                continue\n",
    "            col_index = \"col_\" + str(i)\n",
    "            skin_history[col_index] = [row[\"Weapon\"], row[\"Collection\"], row[\"Quality\"], row[\"Skin\"], condition, st, sv] + price_vol_history\n",
    "            i += 1\n",
    "    if current_num % 100 == 0: # saves the data to csv every 100 items to protect against crashes\n",
    "        print(\"made a new file!\")\n",
    "        skins_prices = pd.DataFrame.from_dict(skin_history, orient = \"index\")\n",
    "        skins_prices.to_excel(\"skins_query/skins{}.xlsx\".format(current_num / 100))\n",
    "        skin_history.clear()\n",
    "\n",
    "if skins_price != {}:\n",
    "    print(\"finished!\")\n",
    "    skins_prices = pd.DataFrame.from_dict(skin_history, orient = \"index\")\n",
    "    skins_prices.to_excel(\"skins_query/skins_final.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stickers Price History Collection\n",
    "\n",
    "Sticker history collection works a bit different from skins. Sticker names have many variants depending on the collection or lack thereof. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stickers = pd.read_excel(\"items_list/stickers_list.xlsx\")\n",
    "\n",
    "all_stickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sticker_hash(collection, skin):\n",
    "    if collection == None:\n",
    "        name = \"Sticker | {0}\".format(skin)\n",
    "    elif \"201\" in collection & (\"community\", \"winter\") not in collection: # if there is a year in the name and is tourney capsule\n",
    "        name = \"Sticker | {0} | {1}\".format(skin, collection)\n",
    "    else:\n",
    "        name = \"Sticker | {0}\".format(skin)\n",
    "\n",
    "    formatted_name = name.replace(\" \", \"%20\") \n",
    "    formatted_name = formatted_name.replace(\"&\", \"%26\")\n",
    "    formatted_name = formatted_name.replace(\"|\", \"%7C\")\n",
    "    formatted_name = formatted_name.replace(\"+\", \"%2B\")\n",
    "    formatted_name = formatted_name.replace(\":\", \"%3A\")\n",
    "    formatted_name = formatted_name.replace(\"/\", \"%2F\")\n",
    "    formatted_name = formatted_name.replace(\"(\", \"%28\")\n",
    "    formatted_name = formatted_name.replace(\")\", \"%29\")\n",
    "\n",
    "    return formatted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sticker_history = {}\n",
    "i = 0\n",
    "current_num = 0\n",
    "total_items = len(all_stickers.index)\n",
    "\n",
    "for index, row in all_stickers.iterrows():\n",
    "    current_num += 1\n",
    "    time.sleep(random.uniform(.5, 3)) # avoid steam rate limiting with a random sleep\n",
    "    name = make_sticker_hash(row[\"Collection\"], row[\"Skin\"])\n",
    "    price_vol_history = get_history(name)\n",
    "    if price_vol_history == 1:\n",
    "        print(\"{0} HAS FAILED\".format(name))\n",
    "        continue\n",
    "    col_index = \"col_\" + str(i)\n",
    "    sticker_history[col_index] = [\"Sticker\", row[\"Collection\"], row[\"Quality\"], row[\"Skin\"], None, None, None] + price_vol_history\n",
    "    i += 1\n",
    "    if current_num % 300 == 0: # saves the data to csv every 100 items to protect against crashes\n",
    "        print(\"made a new file!\")\n",
    "        skins_prices = pd.DataFrame.from_dict(sticker_history, orient = \"index\")\n",
    "        skins_prices.to_excel(\"stickers_query/stickers{}.xlsx\".format(current_num / 300))\n",
    "        sticker_history.clear()\n",
    "\n",
    "if sticker_history != {}:\n",
    "    print(\"finished!\")\n",
    "    skins_prices = pd.DataFrame.from_dict(sticker_history, orient = \"index\")\n",
    "    skins_prices.to_excel(\"stickers_query/stickers_final.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases Price History Collection\n",
    "\n",
    "Cases work with a simple query. Very little changes to name needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases = pd.read_excel(\"items_list/cases_list.xlsx\")\n",
    "\n",
    "all_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_case_hash(skin):\n",
    "    name = skin\n",
    "\n",
    "    formatted_name = name.replace(\" \", \"%20\") \n",
    "    formatted_name = formatted_name.replace(\"&\", \"%26\")\n",
    "    formatted_name = formatted_name.replace(\"|\", \"%7C\")\n",
    "    formatted_name = formatted_name.replace(\"+\", \"%2B\")\n",
    "    formatted_name = formatted_name.replace(\":\", \"%3A\")\n",
    "    formatted_name = formatted_name.replace(\"/\", \"-\")\n",
    "    formatted_name = formatted_name.replace(\"(\", \"%28\")\n",
    "    formatted_name = formatted_name.replace(\")\", \"%29\")\n",
    "\n",
    "    return formatted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "case_history = {}\n",
    "i = 0\n",
    "current_num = 0\n",
    "total_items = len(all_cases.index)\n",
    "\n",
    "for index, row in all_cases.iterrows():\n",
    "    current_num += 1\n",
    "    time.sleep(random.uniform(.5, 3)) # avoid steam rate limiting with a random sleep\n",
    "    name = make_case_hash(row[\"Skin\"])\n",
    "    price_vol_history = get_history(name)\n",
    "    if price_vol_history == 1:\n",
    "        print(\"{0} HAS FAILED\".format(name))\n",
    "        continue\n",
    "    col_index = \"col_\" + str(i)\n",
    "    case_history[col_index] = [row[\"Weapon\"], row[\"Collection\"], None, row[\"Skin\"], None, None, None] + price_vol_history\n",
    "    i += 1\n",
    "    if current_num % 300 == 0: # saves the data to csv every 100 items to protect against crashes\n",
    "        print(\"made a new file!\")\n",
    "        skins_prices = pd.DataFrame.from_dict(case_history, orient = \"index\")\n",
    "        skins_prices.to_excel(\"others_query/cases{}.xlsx\".format(current_num / 300))\n",
    "        case_history.clear()\n",
    "\n",
    "if case_history != {}:\n",
    "    print(\"finished!\")\n",
    "    skins_prices = pd.DataFrame.from_dict(case_history, orient = \"index\")\n",
    "    skins_prices.to_excel(\"others_query/cases_final.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others Price History Collection\n",
    "\n",
    "Others are a bit more finnicky. Music Kits do have a StatTrak variant which much be accounted for by iterating through StatTraks. The various items are also formatted in wildly different ways ways which also must be accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_others = pd.read_excel(\"items_list/others_list.xlsx\")\n",
    "\n",
    "all_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_others_hash(weapon, skin, st):\n",
    "    if (weapon in (\"Agents\", \"Items\", \"Collectible Pins\")) | (\"StatTrak\" in skin): # certain items are formatted properly in list and dont need their weapon added to again\n",
    "        name = skin\n",
    "    else: \n",
    "        name = \"{0} | {1}\".format(weapon, skin)\n",
    "    if st:\n",
    "        name = \"StatTrak™ \" + name\n",
    "\n",
    "    formatted_name = name.replace(\" \", \"%20\") \n",
    "    formatted_name = formatted_name.replace(\"&\", \"%26\")\n",
    "    formatted_name = formatted_name.replace(\"|\", \"%7C\")\n",
    "    formatted_name = formatted_name.replace(\"+\", \"%2B\")\n",
    "    formatted_name = formatted_name.replace(\":\", \"%3A\")\n",
    "    formatted_name = formatted_name.replace(\"/\", \"-\")\n",
    "    formatted_name = formatted_name.replace(\",\", \"%2C\")\n",
    "    formatted_name = formatted_name.replace(\"(\", \"%28\")\n",
    "    formatted_name = formatted_name.replace(\")\", \"%29\")\n",
    "\n",
    "    return formatted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "other_history = {}\n",
    "i = 0\n",
    "current_num = 0\n",
    "total_items = len(all_others.index)\n",
    "\n",
    "for index, row in all_others.iterrows():\n",
    "    current_num += 1\n",
    "    if row[\"StatTrak\"]:\n",
    "        st_opt = (False, True)\n",
    "    else:\n",
    "        st_opt = (False,)\n",
    "    \n",
    "    for st in st_opt:\n",
    "        time.sleep(random.uniform(.5, 3)) # avoid steam rate limiting with a random sleep\n",
    "        name = make_others_hash(row[\"Weapon\"], row[\"Skin\"], st)\n",
    "        price_vol_history = get_history(name)\n",
    "        if price_vol_history == 1:\n",
    "            print(\"{0} HAS FAILED\".format(name))\n",
    "            continue\n",
    "        col_index = \"col_\" + str(i)\n",
    "        other_history[col_index] = [row[\"Weapon\"], row[\"Collection\"], row[\"Quality\"], row[\"Skin\"], None, st, None] + price_vol_history\n",
    "        i += 1\n",
    "    if current_num % 300 == 0: # saves the data to csv every 100 items to protect against crashes\n",
    "        print(\"made a new file!\")\n",
    "        skins_prices = pd.DataFrame.from_dict(other_history, orient = \"index\")\n",
    "        skins_prices.to_excel(\"others_query/others{}.xlsx\".format(current_num / 300))\n",
    "        other_history.clear()\n",
    "\n",
    "if other_history != {}:\n",
    "    print(\"finished!\")\n",
    "    skins_prices = pd.DataFrame.from_dict(other_history, orient = \"index\")\n",
    "    skins_prices.to_excel(\"others_query/others_final2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Data Cleaning\n",
    "\n",
    "A majority of the data cleaning occurs during analysis but before then a multilevel index is added to help organize all the dates. The following cells iterate through each file of chunked up files to create one big dataframe where an index is added and saved as an overarching xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a multilevel index for organizing the days\n",
    "f = np.repeat([d.strftime(\"%Y-%m-%d\") for d in dates_list], 2)\n",
    "first_tier = [\"Weapon\", \"Collection\", \"Quality\", \"Skin\",\"Condition\", \"StatTrak\", \"Souvenir\"]\n",
    "second_tier = [\"\" for x in range(len(first_tier))] + [y for x in range(2602) for y in [\"Price\", \"Volume\"]]\n",
    "first_tier.extend(f)\n",
    "index = pd.MultiIndex.from_arrays([first_tier, second_tier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns all skin files into one big data frame\n",
    "path = r\"D:\\Code\\steam_market_tracker\\skins_query\"\n",
    "all_files = glob.glob(path + \"/*.xlsx\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_excel(filename, index_col = None, header = 0)\n",
    "    li.append(df)\n",
    "\n",
    "skins_history = pd.concat(li, axis = 0, ignore_index = True)\n",
    "\n",
    "del skins_history[\"Unnamed: 0\"] # deletes the column name generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skins_history = skins_history.drop_duplicates()\n",
    "skins_history.columns = index\n",
    "skins_history.to_excel(\"datasets/all_skins.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns all sticker files into one big data frame\n",
    "path = r\"D:\\Code\\steam_market_tracker\\stickerss_query\"\n",
    "all_files = glob.glob(path + \"/*.xlsx\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_excel(filename, index_col = None, header = 0)\n",
    "    li.append(df)\n",
    "\n",
    "stickers_history = pd.concat(li, axis = 0, ignore_index = True)\n",
    "\n",
    "del stickers_history[\"Unnamed: 0\"] # deletes the column name generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stickers_history = stickers_history.drop_duplicates()\n",
    "stickers_history.columns = index\n",
    "stickers_history.to_excel(\"datasets/all_stickers.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns all other files into one big data frame\n",
    "path = r\"D:\\Code\\steam_market_tracker\\others_query\"\n",
    "all_files = glob.glob(path + \"/*.xlsx\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_excel(filename, index_col = None, header = 0)\n",
    "    li.append(df)\n",
    "\n",
    "others_history = pd.concat(li, axis = 0, ignore_index = True)\n",
    "\n",
    "del others_history[\"Unnamed: 0\"] # deletes the column name generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others_history = others_history.drop_duplicates()\n",
    "others_history.columns = index\n",
    "others_history.to_excel(\"datasets/all_others.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Functions\n",
    "\n",
    "The following function was used to clean up data as I originally had forgotten to add a collection and quality column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally forgot to add collection and quality name \n",
    "# ... oops\n",
    "# writes the proper weapon and collection by iterating through the all skins list and comparing it to the price history dataframe\n",
    "# Is used prior to indexing the dataframe\n",
    "\n",
    "frame.insert(1, \"Collection\", None)\n",
    "frame.insert(2, \"Quality\", None)\n",
    "\n",
    "for index, row in all_skins.iterrows():\n",
    "    weapon = row[\"Weapon\"]\n",
    "    collection = row[\"Collection\"]\n",
    "    skin = row[\"Skin\"]\n",
    "    quality = row[\"Quality\"]\n",
    "    certain_skin_index = frame.index[(frame[\"Weapon\"] == weapon) & (frame[\"Skin\"] == skin)].tolist()\n",
    "\n",
    "    for x in certain_skin_index:\n",
    "        frame.iat[x, 1] = collection\n",
    "        frame.iat[x, 2] = quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('datascience': conda)",
   "name": "python_defaultSpec_1600386424832"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}