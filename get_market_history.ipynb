{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Datasets of the Market History of all Counter Strike: Global Offensive Items\n",
    "\n",
    "This notebook includes all the code written to scrape market history from steam json requests. I am still exploring/learning web scraping so the code may not be the best as I tried to experiment with new methods and technologies. Steam has multiple naming irregularities as well as rate limiting that made some manual data cleaning necessary. If you want to rescrape all data, change the values in the third cell of this notebook. Total data scraping time (excluding coding time) was approximately 12 hours. \n",
    "\n",
    "Data is split up into multiple xlsx files to account for potential crashes or errors in data collection (there were many).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinup, slid3, and team role capsules all have 2 versions one with space before () and one without\n",
    "\n",
    "\n",
    "ground rebel elite crew and michael syfers missing space before |\n",
    "\n",
    "scarlxrd has a colon instead of a comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime, date\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings Cell\n",
    "appid = 730 #CSGO\n",
    "currency = 1 # USD\n",
    "country = \"US\"\n",
    "cookie = {\"steamLoginSecure\": \"PLACEHOLDERPLACEHOLDERPLACEHOLDER\"} # steamloginsecure cookie. Please enter in your own for this to work properly\n",
    "\n",
    "FN = \"Factory New\"\n",
    "MW = \"Minimal Wear\"\n",
    "FT = \"Field-Tested\"\n",
    "WW = \"Well-Worn\"\n",
    "BS = \"Battle-Scarred\"\n",
    "\n",
    "starting_date = date(2013, 8, 1) # originally scraped from 8-1-2013 but upon data analysis found the first date of market sales is 8-13-2013\n",
    "ending_date = date(2020, 9, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of dates in the date range for comparison to data pulled from the market later\n",
    "dates_list = pd.date_range(start = starting_date, end = ending_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_history\n",
    "\n",
    "get_history() is the primary function used to pull data from the Steam server using a json get request with the item name and symbols formatted to ASCII. Steam servers will return a status indicating whether the request was successful and a list of prices and the volume sold for each particular date. If a date sold nothing, there is no entry and the list simply skips that date. In order to combat this we use date_list, a list of every date in between our given range. Each date in the date list is compared to the date given in the steam data. If the steam data date does not match, we append a None, None to the price/volume list and increase the date_list index up again until the data has another value. \n",
    "\n",
    "This function underwent multiple revisions. Other possible variants include checking the difference between the current date and the previous date and appending Nones based on that value.\n",
    "\n",
    "Steam also gives hourly? (unsure if hourly but seems so) price data for more recent dates. This means a date can appear multiple times. In order to address this, data with the same date as the previous data entry is aggregated together (price is averaged and volume is summed).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(name):\n",
    "    url = \"http://steamcommunity.com/market/pricehistory/?country={0}&currency={1}&appid={2}&market_hash_name={3}\".format(country, currency, appid, name)\n",
    "\n",
    "    for x in range(3): # occasionally will hit connection errors\n",
    "        try:\n",
    "            item = requests.get(url, cookies = cookie)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            if x == 2:\n",
    "                return 1\n",
    "            else:\n",
    "                time.sleep(60) # waits 60 seconds to allow steam to refresh\n",
    "                continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    item = item.content\n",
    "    item = json.loads(item)\n",
    "\n",
    "    if item: # checks if returned anything\n",
    "        item_prices = item[\"prices\"] \n",
    "        success = item[\"success\"]\n",
    "        if (item_prices == False) | (not item_prices) | (success == False):\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"{0} CURRENTLY SCRAPING ITEM: {1}, NUMBER {2} OF {3} ITEMS\".format(datetime.now(), name, current_num, total_items)) # status check\n",
    "            pricevol = [] # price and volume are combined for multiindexing in the dataframe later\n",
    "            dates = [] # used to check whether dates repeat\n",
    "            item_counter = 0 \n",
    "            date_counter = -1\n",
    "\n",
    "            while (date_counter < len(dates_list) - 1) & (item_counter < len(item_prices)):\n",
    "                date_counter += 1\n",
    "                current_date = datetime.strptime(item_prices[item_counter][0][0:11], \"%b %d %Y\").date()\n",
    "                if (current_date == dates_list[date_counter - 1]): # some entries have multiple entries per day\n",
    "                    pricevol[-2] = np.mean([item_prices[item_counter][1], pricevol[-2]]) # averages the prices in the day and rewrites the previously written one\n",
    "                    pricevol[-1] = int(item_prices[item_counter][2]) + pricevol[-1] # adds the volumes for the day together\n",
    "                    date_counter -= 1\n",
    "                    item_counter += 1\n",
    "                elif dates_list[date_counter] != current_date:\n",
    "                    pricevol.extend((None, None))\n",
    "                else:\n",
    "                    pricevol.append(item_prices[item_counter][1]) # appending price\n",
    "                    pricevol.append(int(item_prices[item_counter][2])) # appending volume\n",
    "                    dates.append(current_date) # appending the date into a list\n",
    "                    item_counter += 1\n",
    "        \n",
    "            if current_date != ending_date: # adds extra nones to end if the present has no sales\n",
    "                diff = ending_date - current_date\n",
    "                pricevol.extend([None for x in range(0, diff.days * 2)])\n",
    "    else:\n",
    "        print(\"No contents on {}\".format(name))\n",
    "        return 1\n",
    "    return pricevol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weapon Skins Price History Collection\n",
    "\n",
    "Scraping weapon skins involves formatting the skin's name and iterating through all possible conditions, souvenir, and StatTrak variants. Note that this scrapes through all possible conditions. Many items do not have a certain condition in which this code will call it failed and move on to the next item.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_skins = pd.read_excel(\"items_list/skins_list.xlsx\", index_col = 0)\n",
    "\n",
    "knives = pd.read_excel(\"items_list/knivesgloves_list.xlsx\", index_col = 0)\n",
    "all_skins = all_skins.append(knives, ignore_index = True)\n",
    "\n",
    "all_skins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_skins = all_skins.drop(all_skins.index[0:1289]) # in case something goes wrong you can slice the dataframe and continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hash_name(weapon, skin, quality, condition, st, sv):\n",
    "    if skin == \"★ (Vanilla)\":\n",
    "        name = \"{0}\".format(weapon) # vanilla knives have no condition or skin name\n",
    "    else:\n",
    "        name = \"{0} | {1} ({2})\".format(weapon, skin, condition)\n",
    "        \n",
    "    if st == True:\n",
    "        name = \"StatTrak™ \" + name\n",
    "    elif sv == True: \n",
    "        name = \"Souvenir \" + name\n",
    "        \n",
    "    if quality in (\"Extraordinary\", \"Covert\"): # knives and gloves have a star before their name\n",
    "        name = \"★ \" + name\n",
    "        \n",
    "    formatted_name = name.replace(\" \", \"%20\") \n",
    "    formatted_name = formatted_name.replace(\"&\", \"%26\")\n",
    "    formatted_name = formatted_name.replace(\"|\", \"%7C\")\n",
    "    formatted_name = formatted_name.replace(\"+\", \"%2B\")\n",
    "    formatted_name = formatted_name.replace(\":\", \"%3A\")\n",
    "    formatted_name = formatted_name.replace(\"/\", \"%2F\")\n",
    "    formatted_name = formatted_name.replace(\"(\", \"%28\")\n",
    "    formatted_name = formatted_name.replace(\")\", \"%29\")\n",
    "\n",
    "    return formatted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_history = {}\n",
    "i = 0\n",
    "current_num = 0\n",
    "total_items = len(all_skins.index)\n",
    "\n",
    "for index, row in all_skins.iterrows():\n",
    "    current_num += 1\n",
    "    # checks whether to reiterate for stattrak and souvenir\n",
    "    if (row[\"StatTrak\"] == True) | (row[\"Souvenir\"] == True):\n",
    "        svst = ((False, False), (row[\"StatTrak\"], row[\"Souvenir\"]))\n",
    "    else:\n",
    "        svst = ((False, False),)\n",
    "    for st, sv in svst:\n",
    "        if row[\"Skin\"] == \"★ (Vanilla)\":\n",
    "            possible_conditions = (None,)\n",
    "        else:\n",
    "            possible_conditions = (BS, WW, FT , MW , FN)\n",
    "        for condition in possible_conditions: # iterates through all possible conditions\n",
    "            time.sleep(random.uniform(.5, 3)) # avoid steam rate limiting with a random sleep\n",
    "            name = make_hash_name(row[\"Weapon\"], row[\"Skin\"], row[\"Quality\"] condition, st, sv)\n",
    "            price_vol_history = get_history(name)\n",
    "            if price_vol_history == 1:\n",
    "                print(\"{0} HAS FAILED\".format(name))\n",
    "                continue\n",
    "            col_index = \"col_\" + str(i)\n",
    "            skin_history[col_index] = [row[\"Weapon\"], row[\"Collection\"], row[\"Quality\"], row[\"Skin\"], condition, st, sv] + price_vol_history\n",
    "            i += 1\n",
    "    if current_num % 100 == 0: # saves the data to csv every 100 items to protect against crashes\n",
    "        print(\"made a new file!\")\n",
    "        skins_prices = pd.DataFrame.from_dict(skin_history, orient = \"index\")\n",
    "        skins_prices.to_excel(\"skins_query/skins{}.xlsx\".format(current_num / 100))\n",
    "        skin_history.clear()\n",
    "\n",
    "if skin_history != {}:\n",
    "    print(\"finished!\")\n",
    "    skins_prices = pd.DataFrame.from_dict(skin_history, orient = \"index\")\n",
    "    skins_prices.to_excel(\"skins_query/skins_final.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stickers Price History Collection\n",
    "\n",
    "Sticker history collection works a bit different from skins. Sticker names have many variants depending on the collection or lack thereof. We want to separate the collections from each other to use in data analysis later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stickers = pd.read_excel(\"items_list/stickers_list.xlsx\")\n",
    "\n",
    "all_stickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sticker_hash(collection, skin):\n",
    "    if (\"Community\" in collection) | (\"Winter\" in skin): # for community 2018 capsules and dreamhack winter 2014 sticker\n",
    "        name = \"Sticker | {0}\".format(skin)\n",
    "    elif (\"201\" in collection): # if there is a year in the name and is tourney capsule\n",
    "        name = \"Sticker | {0} | {1}\".format(skin, collection)\n",
    "    else:\n",
    "        name = \"Sticker | {0}\".format(skin)\n",
    "\n",
    "    formatted_name = name.replace(\" \", \"%20\") \n",
    "    formatted_name = formatted_name.replace(\"&\", \"%26\")\n",
    "    formatted_name = formatted_name.replace(\"|\", \"%7C\")\n",
    "    formatted_name = formatted_name.replace(\"+\", \"%2B\")\n",
    "    formatted_name = formatted_name.replace(\":\", \"%3A\")\n",
    "    formatted_name = formatted_name.replace(\"/\", \"%2F\")\n",
    "    formatted_name = formatted_name.replace(\"(\", \"%28\")\n",
    "    formatted_name = formatted_name.replace(\")\", \"%29\")\n",
    "\n",
    "    return formatted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticker_history = {}\n",
    "i = 0\n",
    "current_num = 0\n",
    "total_items = len(all_stickers.index)\n",
    "\n",
    "for index, row in all_stickers.iterrows():\n",
    "    current_num += 1\n",
    "    time.sleep(random.uniform(.5, 3)) # avoid steam rate limiting with a random sleep\n",
    "    name = make_sticker_hash(row[\"Collection\"], row[\"Skin\"])\n",
    "    price_vol_history = get_history(name)\n",
    "    if price_vol_history == 1:\n",
    "        print(\"{0} HAS FAILED\".format(name))\n",
    "        continue\n",
    "    col_index = \"col_\" + str(i)\n",
    "    sticker_history[col_index] = [\"Sticker\", row[\"Collection\"], row[\"Quality\"], row[\"Skin\"], None, None, None] + price_vol_history\n",
    "    i += 1\n",
    "    if current_num % 300 == 0: # saves the data to csv every 300 items to protect against crashes\n",
    "        print(\"made a new file!\")\n",
    "        skins_prices = pd.DataFrame.from_dict(sticker_history, orient = \"index\")\n",
    "        skins_prices.to_excel(\"stickers_query/stickers{}.xlsx\".format(current_num / 300))\n",
    "        sticker_history.clear()\n",
    "\n",
    "if sticker_history != {}:\n",
    "    print(\"finished!\")\n",
    "    skins_prices = pd.DataFrame.from_dict(sticker_history, orient = \"index\")\n",
    "    skins_prices.to_excel(\"stickers_query/stickers_final.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases Price History Collection\n",
    "\n",
    "Cases work with a simple query. Very little changes to name needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases = pd.read_excel(\"items_list/cases_list.xlsx\", index_col = 0)\n",
    "\n",
    "all_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_case_hash(skin):\n",
    "    name = skin\n",
    "\n",
    "    formatted_name = name.replace(\" \", \"%20\") \n",
    "    formatted_name = formatted_name.replace(\"&\", \"%26\")\n",
    "    formatted_name = formatted_name.replace(\"|\", \"%7C\")\n",
    "    formatted_name = formatted_name.replace(\"+\", \"%2B\")\n",
    "    formatted_name = formatted_name.replace(\":\", \"%3A\")\n",
    "    formatted_name = formatted_name.replace(\"/\", \"-\")\n",
    "    formatted_name = formatted_name.replace(\"(\", \"%28\")\n",
    "    formatted_name = formatted_name.replace(\")\", \"%29\")\n",
    "\n",
    "    return formatted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_history = {}\n",
    "i = 0\n",
    "current_num = 0\n",
    "total_items = len(all_cases.index)\n",
    "\n",
    "for index, row in all_cases.iterrows():\n",
    "    current_num += 1\n",
    "    time.sleep(random.uniform(.5, 3)) # avoid steam rate limiting with a random sleep\n",
    "    name = make_case_hash(row[\"Skin\"])\n",
    "    price_vol_history = get_history(name)\n",
    "    if price_vol_history == 1:\n",
    "        print(\"{0} HAS FAILED\".format(name))\n",
    "        continue\n",
    "    col_index = \"col_\" + str(i)\n",
    "    case_history[col_index] = [row[\"Weapon\"], row[\"Collection\"], None, row[\"Skin\"], None, None, None] + price_vol_history\n",
    "    i += 1\n",
    "    if current_num % 300 == 0: # saves the data to csv every 100 items to protect against crashes\n",
    "        print(\"made a new file!\")\n",
    "        skins_prices = pd.DataFrame.from_dict(case_history, orient = \"index\")\n",
    "        skins_prices.to_excel(\"others_query/cases{}.xlsx\".format(current_num / 300))\n",
    "        case_history.clear()\n",
    "\n",
    "if case_history != {}:\n",
    "    print(\"finished!\")\n",
    "    skins_prices = pd.DataFrame.from_dict(case_history, orient = \"index\")\n",
    "    skins_prices.to_excel(\"others_query/cases_final.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others Price History Collection\n",
    "\n",
    "Others are a bit more finnicky. Music Kits do have a StatTrak variant which much be accounted for by iterating through StatTraks. The various items are also formatted in wildly different ways ways which also must be accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_others = pd.read_excel(\"items_list/others_list.xlsx\", index_col = 0)\n",
    "\n",
    "all_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_others_hash(weapon, skin, st):\n",
    "    if (weapon in (\"Agents\", \"Items\", \"Collectible Pins\")) | (\"StatTrak\" in skin): # certain items are formatted properly in list and dont need their weapon added to again\n",
    "        name = skin\n",
    "    else: \n",
    "        name = \"{0} | {1}\".format(weapon, skin)\n",
    "    if st:\n",
    "        name = \"StatTrak™ \" + name\n",
    "\n",
    "    formatted_name = name.replace(\" \", \"%20\") \n",
    "    formatted_name = formatted_name.replace(\"&\", \"%26\")\n",
    "    formatted_name = formatted_name.replace(\"|\", \"%7C\")\n",
    "    formatted_name = formatted_name.replace(\"+\", \"%2B\")\n",
    "    formatted_name = formatted_name.replace(\":\", \"%3A\")\n",
    "    formatted_name = formatted_name.replace(\"/\", \"-\")\n",
    "    formatted_name = formatted_name.replace(\",\", \"%2C\")\n",
    "    formatted_name = formatted_name.replace(\"(\", \"%28\")\n",
    "    formatted_name = formatted_name.replace(\")\", \"%29\")\n",
    "\n",
    "    return formatted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_history = {}\n",
    "i = 0\n",
    "current_num = 0\n",
    "total_items = len(all_others.index)\n",
    "\n",
    "for index, row in all_others.iterrows():\n",
    "    current_num += 1\n",
    "    if row[\"StatTrak\"]:\n",
    "        st_opt = (False, True)\n",
    "    else:\n",
    "        st_opt = (False,)\n",
    "    \n",
    "    for st in st_opt:\n",
    "        time.sleep(random.uniform(.5, 3)) # avoid steam rate limiting with a random sleep\n",
    "        name = make_others_hash(row[\"Weapon\"], row[\"Skin\"], st)\n",
    "        price_vol_history = get_history(name)\n",
    "        if price_vol_history == 1:\n",
    "            print(\"{0} HAS FAILED\".format(name))\n",
    "            continue\n",
    "        col_index = \"col_\" + str(i)\n",
    "        other_history[col_index] = [row[\"Weapon\"], row[\"Collection\"], row[\"Quality\"], row[\"Skin\"], None, st, None] + price_vol_history\n",
    "        i += 1\n",
    "    if current_num % 300 == 0: # saves the data to csv every 100 items to protect against crashes\n",
    "        print(\"made a new file!\")\n",
    "        skins_prices = pd.DataFrame.from_dict(other_history, orient = \"index\")\n",
    "        skins_prices.to_excel(\"others_query/others{}.xlsx\".format(current_num / 300))\n",
    "        other_history.clear()\n",
    "\n",
    "if other_history != {}:\n",
    "    print(\"finished!\")\n",
    "    skins_prices = pd.DataFrame.from_dict(other_history, orient = \"index\")\n",
    "    skins_prices.to_excel(\"others_query/others_final.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Data Cleaning\n",
    "\n",
    "A majority of the data cleaning occurs during analysis but before then a multilevel index is added to help organize all the dates. The following cells iterate through each file of chunked up files to create one big dataframe where an index is added and saved as an overarching xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a multilevel index for organizing the days\n",
    "f = np.repeat([d.strftime(\"%Y-%m-%d\") for d in dates_list], 2)\n",
    "first_tier = [\"Weapon\", \"Collection\", \"Quality\", \"Skin\",\"Condition\", \"StatTrak\", \"Souvenir\"]\n",
    "second_tier = [\"\" for x in range(len(first_tier))] + [y for x in range(2602) for y in [\"Price\", \"Volume\"]]\n",
    "first_tier.extend(f)\n",
    "index = pd.MultiIndex.from_arrays([first_tier, second_tier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns all skin files into one big data frame\n",
    "path = r\"D:\\Code\\steam_market_tracker\\skins_query\"\n",
    "all_files = glob.glob(path + \"/*.xlsx\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_excel(filename, index_col = 0, header = 0)\n",
    "    li.append(df)\n",
    "\n",
    "skins_history = pd.concat(li, axis = 0, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skins_history = skins_history.drop_duplicates()\n",
    "skins_history.columns = index\n",
    "skins_history.to_excel(\"datasets/all_skins.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"D:\\Code\\steam_market_tracker\\stickers_query\"\n",
    "all_files = glob.glob(path + \"/*.xlsx\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_excel(filename, index_col = 0, header = 0)\n",
    "    li.append(df)\n",
    "\n",
    "stickers_history = pd.concat(li, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stickers_history = stickers_history.drop_duplicates()\n",
    "stickers_history.columns = index\n",
    "stickers_history.to_excel(\"datasets/all_stickers.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns all other files into one big data frame\n",
    "path = r\"D:\\Code\\steam_market_tracker\\others_query\"\n",
    "all_files = glob.glob(path + \"/*.xlsx\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_excel(filename, index_col = 0, header = 0)\n",
    "    li.append(df)\n",
    "\n",
    "others_history = pd.concat(li, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others_history = others_history.drop_duplicates()\n",
    "others_history.columns = index\n",
    "others_history.to_excel(\"datasets/all_others.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Functions\n",
    "\n",
    "The following function was used to clean up data as I originally had forgotten to add a collection and quality column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally forgot to add collection and quality name \n",
    "# ... oops\n",
    "# writes the proper weapon and collection by iterating through the all skins list and comparing it to the price history dataframe\n",
    "# Is used prior to indexing the dataframe\n",
    "\n",
    "frame.insert(1, \"Collection\", None)\n",
    "frame.insert(2, \"Quality\", None)\n",
    "\n",
    "for index, row in all_skins.iterrows():\n",
    "    weapon = row[\"Weapon\"]\n",
    "    collection = row[\"Collection\"]\n",
    "    skin = row[\"Skin\"]\n",
    "    quality = row[\"Quality\"]\n",
    "    certain_skin_index = frame.index[(frame[\"Weapon\"] == weapon) & (frame[\"Skin\"] == skin)].tolist()\n",
    "\n",
    "    for x in certain_skin_index:\n",
    "        frame.iat[x, 1] = collection\n",
    "        frame.iat[x, 2] = quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
